#!/usr/bin/env python3
"""
KEGGæ•°æ®è®­ç»ƒè„šæœ¬ - ç®€åŒ–ç‰ˆæœ¬
ä¸“é—¨ç”¨äºå¤„ç†KEGGçœŸå®æ•°æ®çš„è®­ç»ƒ
"""

import os
import pandas as pd
import json
import torch
import numpy as np
from pathlib import Path
from torch.utils.data import DataLoader
from config import DataConfig, ModelConfig, TrainingConfig
from data_adapter import KEGGDataAdapter, KEGGDataset, collate_kegg_batch, prepare_kegg_data_for_training
from models import KEGGGraphModel, create_kegg_model
from trainer import LinkPredictionTrainer, create_trainer
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def load_kegg_data(data_dir):
    """åŠ è½½å¤„ç†åçš„KEGGæ•°æ®"""
    logger.info("ğŸ”§ åŠ è½½KEGGæ•°æ®...")
    
    # è¯»å–èŠ‚ç‚¹æ•°æ®
    nodes_file = Path(data_dir) / "processed_nodes.csv"
    edges_file = Path(data_dir) / "processed_edges.csv"
    weights_file = Path(data_dir) / "processed_weights.json"
    
    nodes_df = pd.read_csv(nodes_file)
    edges_df = pd.read_csv(edges_file)
    
    with open(weights_file, 'r') as f:
        weights_data = json.load(f)
    
    logger.info(f"   èŠ‚ç‚¹æ•°: {len(nodes_df)}")
    logger.info(f"   è¾¹æ•°: {len(edges_df)}")
    logger.info(f"   æƒé‡æ•°: {len(weights_data)}")
    
    return nodes_df, edges_df, weights_data

def create_simple_config(nodes_count, edges_count):
    """åˆ›å»ºç®€åŒ–çš„é…ç½®"""
    
    # æ•°æ®é…ç½®
    data_config = DataConfig(
        data_dir="kegg_real_processed",
        nodes_file="processed_nodes.csv",
        edges_file="processed_edges.csv",
        weights_file="processed_weights.json"
    )
    
    # æ¨¡å‹é…ç½® - ç®€åŒ–å‚æ•°
    model_config = ModelConfig(
        model_type="GraphSAGE",
        input_dim=8,  # æ ¹æ®å®é™…ç‰¹å¾ç»´åº¦è°ƒæ•´
        hidden_dim=64,
        output_dim=32,
        num_layers=3,
        dropout=0.3
    )
    
    # è®­ç»ƒé…ç½® - ç®€åŒ–è®­ç»ƒ
    training_config = TrainingConfig(
        epochs=500,       # é€‚å½“çš„è®­ç»ƒè½®æ•°
        learning_rate=0.01,
        weight_decay=1e-4,
        patience=10,
        early_stopping=True
    )
    
    return data_config, model_config, training_config

def train_kegg_model():
    """è®­ç»ƒKEGGæ¨¡å‹"""
    
    # åˆ›å»ºç»“æœç›®å½•
    results_dir = "kegg_training_results"
    os.makedirs(results_dir, exist_ok=True)
    
    try:
        # 1. åŠ è½½æ•°æ®
        nodes_df, edges_df, weights_data = load_kegg_data("kegg_real_processed")
        
        # 2. åˆ›å»ºé…ç½®
        data_config, model_config, training_config = create_simple_config(
            len(nodes_df), len(edges_df)
        )
        
        # 3. å‡†å¤‡æ•°æ®
        logger.info("ğŸ”„ å‡†å¤‡è®­ç»ƒæ•°æ®...")
        from data_adapter import prepare_kegg_data_for_training
        
        data_dict = prepare_kegg_data_for_training("kegg_real_processed", data_config)
        
        train_dataset = data_dict['train_dataset']
        val_dataset = data_dict['val_dataset']
        test_dataset = data_dict['test_dataset']
        graph_data = data_dict['graph_data']
        
        # 4. åˆ›å»ºæ•°æ®åŠ è½½å™¨
        from torch.utils.data import DataLoader
        
        train_loader = DataLoader(
            train_dataset, 
            batch_size=training_config.batch_size, 
            shuffle=True,
            collate_fn=collate_kegg_batch
        )
        
        val_loader = DataLoader(
            val_dataset, 
            batch_size=training_config.batch_size, 
            shuffle=False,
            collate_fn=collate_kegg_batch
        )
        
        test_loader = DataLoader(
            test_dataset, 
            batch_size=training_config.batch_size, 
            shuffle=False,
            collate_fn=collate_kegg_batch
        )
        
        # 5. åˆ›å»ºæ¨¡å‹
        logger.info("ğŸ§  åˆ›å»ºæ¨¡å‹...")
        from models import create_kegg_model
        
        # æ›´æ–°æ¨¡å‹é…ç½®çš„è¾“å…¥ç»´åº¦
        model_config.input_dim = graph_data['x'].shape[1]
        model = create_kegg_model(model_config)
        
        # 6. åˆ›å»ºè®­ç»ƒå™¨
        logger.info("ğŸƒ åˆ›å»ºè®­ç»ƒå™¨...")
        from trainer import create_trainer
        
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        logger.info(f"   ä½¿ç”¨è®¾å¤‡: {device}")
        
        trainer = create_trainer(model, training_config, device)
        
        # 7. å¼€å§‹è®­ç»ƒ
        logger.info("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        training_results = trainer.train(train_loader, val_loader, graph_data)
        
        # 8. è¯„ä¼°æ¨¡å‹
        logger.info("ğŸ“Š è¯„ä¼°æ¨¡å‹...")
        test_results = trainer.evaluate(test_loader, graph_data)
        
        # 9. ä¿å­˜ç»“æœ
        results = {
            'training_results': training_results,
            'test_results': test_results,
            'model_config': model_config.__dict__,
            'training_config': training_config.__dict__,
            'data_config': data_config.__dict__
        }
        
        results_file = os.path.join(results_dir, "training_results.json")
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        # 10. ä¿å­˜æ¨¡å‹
        model_file = os.path.join(results_dir, "best_model.pth")
        trainer.save_model(model_file)
        
        # 11. ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        if training_config.save_plots:
            plot_file = os.path.join(results_dir, "training_curves.png")
            trainer.plot_training_curves(plot_file)
        
        logger.info("âœ… è®­ç»ƒå®Œæˆ!")
        logger.info(f"   æœ€ä½³éªŒè¯AUC: {training_results['best_val_auc']:.4f}")
        logger.info(f"   æµ‹è¯•AUC: {test_results.get('auc_roc', 0):.4f}")
        logger.info(f"   ç»“æœä¿å­˜åœ¨: {results_dir}")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    train_kegg_model()