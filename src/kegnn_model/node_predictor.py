#!/usr/bin/env python3
"""
åŸºäºGNNæ¨¡å‹çš„KEGGèŠ‚ç‚¹é¢„æµ‹å™¨
æ•´åˆpathway_discoveryåŠŸèƒ½ï¼Œæ”¯æŒKOåºåˆ—åˆ°èŠ‚ç‚¹é¢„æµ‹çš„å®Œæ•´æµç¨‹

ä¸»è¦åŠŸèƒ½ï¼š
1. KOåºåˆ—è¾“å…¥å’ŒæŠ½è±¡èŠ‚ç‚¹æ˜ å°„
2. åŸºäºGNNæ¨¡å‹çš„èŠ‚ç‚¹è¿æ¥é¢„æµ‹
3. ä»£è°¢é€šè·¯æ¨ç†å’Œè·¯å¾„å‘ç°
4. èŠ‚ç‚¹ç‰¹å¾åˆ†æå’Œå¯è§†åŒ–
"""

import sys
import os
import logging
import json
import numpy as np
import torch
import pandas as pd
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional, Any
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥å¿…è¦æ¨¡å—
from predict_kegg import KEGGPredictor
from data_adapter import KEGGDataAdapter
from config import ModelConfig

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class KEGGNodePredictor:
    """KEGGèŠ‚ç‚¹é¢„æµ‹å™¨ - åŸºäºGNNæ¨¡å‹"""
    
    def __init__(self, 
                 model_path: str = "kegg_training_results/best_model.pth",
                 data_dir: str = "kegg_real_processed"):
        """
        åˆå§‹åŒ–èŠ‚ç‚¹é¢„æµ‹å™¨
        
        Args:
            model_path: è®­ç»ƒå¥½çš„GNNæ¨¡å‹è·¯å¾„
            data_dir: KEGGæ•°æ®ç›®å½•
        """
        self.model_path = model_path
        self.data_dir = data_dir
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        logger.info("ğŸš€ åˆå§‹åŒ–KEGGèŠ‚ç‚¹é¢„æµ‹å™¨...")
        logger.info(f"   æ¨¡å‹è·¯å¾„: {model_path}")
        logger.info(f"   æ•°æ®ç›®å½•: {data_dir}")
        logger.info(f"   è®¡ç®—è®¾å¤‡: {self.device}")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._load_predictor()
        self._load_node_data()
        
    def _load_predictor(self):
        """åŠ è½½GNNé¢„æµ‹å™¨"""
        try:
            logger.info("ğŸ”§ åŠ è½½GNNé¢„æµ‹å™¨...")
            self.predictor = KEGGPredictor(self.model_path)
            logger.info("âœ… GNNé¢„æµ‹å™¨åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ GNNé¢„æµ‹å™¨åŠ è½½å¤±è´¥: {e}")
            raise
            
    def _load_node_data(self):
        """åŠ è½½èŠ‚ç‚¹æ•°æ®"""
        try:
            logger.info("ğŸ“Š åŠ è½½èŠ‚ç‚¹æ•°æ®...")
            
            # åŠ è½½èŠ‚ç‚¹ä¿¡æ¯
            nodes_file = os.path.join(self.data_dir, "processed_nodes.csv")
            self.nodes_df = pd.read_csv(nodes_file)
            
            # åˆ›å»ºèŠ‚ç‚¹æ˜ å°„
            self.node_to_idx = {node: idx for idx, node in enumerate(self.nodes_df['node_id'])}
            self.idx_to_node = {idx: node for node, idx in self.node_to_idx.items()}
            
            # è·å–æ‰€æœ‰èŠ‚ç‚¹åˆ—è¡¨
            self.all_nodes = list(self.nodes_df['node_id'])
            
            logger.info(f"âœ… èŠ‚ç‚¹æ•°æ®åŠ è½½æˆåŠŸ: {len(self.all_nodes)} ä¸ªèŠ‚ç‚¹")
            
        except Exception as e:
            logger.error(f"âŒ èŠ‚ç‚¹æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def predict_node_connections(self, 
                               target_node: str, 
                               candidate_nodes: Optional[List[str]] = None,
                               top_k: int = 10,
                               min_probability: float = 0.1) -> Dict:
        """
        é¢„æµ‹ç›®æ ‡èŠ‚ç‚¹ä¸å€™é€‰èŠ‚ç‚¹çš„è¿æ¥æ¦‚ç‡
        
        Args:
            target_node: ç›®æ ‡èŠ‚ç‚¹ID
            candidate_nodes: å€™é€‰èŠ‚ç‚¹åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ‰€æœ‰èŠ‚ç‚¹
            top_k: è¿”å›å‰Kä¸ªæœ€å¯èƒ½çš„è¿æ¥
            min_probability: æœ€å°æ¦‚ç‡é˜ˆå€¼
            
        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        logger.info(f"ğŸ¯ é¢„æµ‹èŠ‚ç‚¹è¿æ¥: {target_node}")
        
        if target_node not in self.all_nodes:
            logger.error(f"âŒ ç›®æ ‡èŠ‚ç‚¹ä¸å­˜åœ¨: {target_node}")
            return {'error': f'ç›®æ ‡èŠ‚ç‚¹ä¸å­˜åœ¨: {target_node}'}
        
        # ç¡®å®šå€™é€‰èŠ‚ç‚¹
        if candidate_nodes is None:
            candidate_nodes = [node for node in self.all_nodes if node != target_node]
        else:
            # éªŒè¯å€™é€‰èŠ‚ç‚¹
            valid_candidates = [node for node in candidate_nodes if node in self.all_nodes and node != target_node]
            if len(valid_candidates) != len(candidate_nodes):
                logger.warning(f"âš ï¸  éƒ¨åˆ†å€™é€‰èŠ‚ç‚¹æ— æ•ˆï¼Œæœ‰æ•ˆå€™é€‰èŠ‚ç‚¹: {len(valid_candidates)}")
            candidate_nodes = valid_candidates
        
        logger.info(f"ğŸ“‹ å€™é€‰èŠ‚ç‚¹æ•°é‡: {len(candidate_nodes)}")
        
        # æ‰¹é‡é¢„æµ‹è¿æ¥æ¦‚ç‡
        pairs = [(target_node, candidate) for candidate in candidate_nodes]
        predictions = self.predictor.predict_batch(pairs)
        
        # è¿‡æ»¤å’Œæ’åºç»“æœ
        results = []
        for (source, target), probability in predictions.items():
            if probability >= min_probability:
                confidence = self._get_confidence_level(probability)
                results.append({
                    'target_node': target,
                    'probability': probability,
                    'confidence': confidence,
                    'prediction': 'Connected' if probability > 0.5 else 'Not Connected'
                })
        
        # æŒ‰æ¦‚ç‡æ’åº
        results.sort(key=lambda x: x['probability'], reverse=True)
        
        # è¿”å›å‰Kä¸ªç»“æœ
        top_results = results[:top_k]
        
        return {
            'query_node': target_node,
            'total_candidates': len(candidate_nodes),
            'valid_predictions': len(results),
            'top_connections': top_results,
            'statistics': {
                'max_probability': max([r['probability'] for r in results]) if results else 0,
                'min_probability': min([r['probability'] for r in results]) if results else 0,
                'avg_probability': np.mean([r['probability'] for r in results]) if results else 0,
                'connected_count': len([r for r in results if r['prediction'] == 'Connected']),
                'high_confidence_count': len([r for r in results if r['confidence'] == 'High'])
            }
        }
    
    def predict_pathway_from_nodes(self, 
                                 node_sequence: List[str],
                                 max_path_length: int = 10,
                                 min_probability: float = 0.1) -> Dict:
        """
        ä»èŠ‚ç‚¹åºåˆ—é¢„æµ‹ä»£è°¢é€šè·¯
        
        Args:
            node_sequence: èŠ‚ç‚¹åºåˆ—
            max_path_length: æœ€å¤§è·¯å¾„é•¿åº¦
            min_probability: æœ€å°è¾¹æ¦‚ç‡é˜ˆå€¼
            
        Returns:
            é€šè·¯é¢„æµ‹ç»“æœ
        """
        logger.info(f"ğŸ›¤ï¸  é¢„æµ‹ä»£è°¢é€šè·¯: {len(node_sequence)} ä¸ªèŠ‚ç‚¹")
        logger.info(f"ğŸ“‹ èŠ‚ç‚¹åºåˆ—: {node_sequence}")
        
        # éªŒè¯èŠ‚ç‚¹
        valid_nodes = [node for node in node_sequence if node in self.all_nodes]
        if len(valid_nodes) != len(node_sequence):
            invalid_nodes = [node for node in node_sequence if node not in self.all_nodes]
            logger.warning(f"âš ï¸  æ— æ•ˆèŠ‚ç‚¹: {invalid_nodes}")
        
        if len(valid_nodes) < 2:
            return {'error': 'è‡³å°‘éœ€è¦2ä¸ªæœ‰æ•ˆèŠ‚ç‚¹'}
        
        # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„æœ‰å‘è¾¹ï¼ˆä¸åŒ…å«è‡ªç¯ï¼‰
        edges_to_predict = []
        for i in range(len(valid_nodes)):
            for j in range(len(valid_nodes)):
                if i != j:
                    edges_to_predict.append((valid_nodes[i], valid_nodes[j]))
        
        logger.info(f"ğŸ”— é¢„æµ‹è¾¹æ•°é‡: {len(edges_to_predict)}")
        
        # æ‰¹é‡é¢„æµ‹è¾¹æ¦‚ç‡
        edge_predictions = self.predictor.predict_batch_pairs(edges_to_predict)
        
        # å°†è¾¹é¢„æµ‹ç»“æœè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        edge_dict = {}
        for i, (node1, node2) in enumerate(edges_to_predict):
            edge_key = (node1, node2)
            edge_dict[edge_key] = edge_predictions[i]['connection_probability']
        
        # æ„å»ºè·¯å¾„ï¼ˆä½¿ç”¨æœ‰å‘è¾¹ï¼Œè·¯å¾„é•¿åº¦ä¸Šé™ä¸è¶…è¿‡å”¯ä¸€èŠ‚ç‚¹æ•°ï¼‰
        pathways = self._build_pathways(valid_nodes, edge_dict, max_path_length, min_probability)
        
        return {
            'input_nodes': node_sequence,
            'valid_nodes': valid_nodes,
            'total_edges_predicted': len(edges_to_predict),
            'pathways': pathways,
            'edge_predictions': {f"{edge[0]}-{edge[1]}": prob for edge, prob in edge_dict.items()},
            'statistics': {
                'total_pathways': len(pathways),
                'avg_pathway_score': np.mean([p['score'] for p in pathways]) if pathways else 0,
                'max_pathway_score': max([p['score'] for p in pathways]) if pathways else 0
            }
        }
    
    def find_connecting_nodes(self, 
                            source_node: str, 
                            target_node: str,
                            max_intermediate_nodes: int = 3,
                            min_probability: float = 0.3) -> Dict:
        """
        å¯»æ‰¾è¿æ¥ä¸¤ä¸ªèŠ‚ç‚¹çš„ä¸­é—´èŠ‚ç‚¹
        
        Args:
            source_node: æºèŠ‚ç‚¹
            target_node: ç›®æ ‡èŠ‚ç‚¹
            max_intermediate_nodes: æœ€å¤§ä¸­é—´èŠ‚ç‚¹æ•°
            min_probability: æœ€å°è¿æ¥æ¦‚ç‡
            
        Returns:
            è¿æ¥è·¯å¾„ç»“æœ
        """
        logger.info(f"ğŸ” å¯»æ‰¾è¿æ¥è·¯å¾„: {source_node} â†’ {target_node}")
        
        if source_node not in self.all_nodes or target_node not in self.all_nodes:
            return {'error': 'æºèŠ‚ç‚¹æˆ–ç›®æ ‡èŠ‚ç‚¹ä¸å­˜åœ¨'}
        
        # ç›´æ¥è¿æ¥æ£€æŸ¥
        direct_prob = self.predictor.predict_single_pair(source_node, target_node)['probability']
        
        paths = []
        
        # æ·»åŠ ç›´æ¥è¿æ¥
        if direct_prob >= min_probability:
            paths.append({
                'path': [source_node, target_node],
                'length': 1,
                'total_probability': direct_prob,
                'avg_probability': direct_prob,
                'edges': [{'from': source_node, 'to': target_node, 'probability': direct_prob}]
            })
        
        # å¯»æ‰¾é€šè¿‡ä¸­é—´èŠ‚ç‚¹çš„è·¯å¾„
        for num_intermediate in range(1, max_intermediate_nodes + 1):
            intermediate_paths = self._find_paths_with_intermediates(
                source_node, target_node, num_intermediate, min_probability
            )
            paths.extend(intermediate_paths)
        
        # æŒ‰æ€»æ¦‚ç‡æ’åº
        paths.sort(key=lambda x: x['total_probability'], reverse=True)
        
        return {
            'source_node': source_node,
            'target_node': target_node,
            'direct_connection': {
                'probability': direct_prob,
                'exists': direct_prob >= min_probability
            },
            'connecting_paths': paths[:10],  # è¿”å›å‰10ä¸ªæœ€ä½³è·¯å¾„
            'statistics': {
                'total_paths_found': len(paths),
                'best_path_probability': paths[0]['total_probability'] if paths else 0,
                'avg_path_length': np.mean([p['length'] for p in paths]) if paths else 0
            }
        }
    
    def analyze_node_features(self, node_id: str) -> Dict:
        """
        åˆ†æèŠ‚ç‚¹ç‰¹å¾
        
        Args:
            node_id: èŠ‚ç‚¹ID
            
        Returns:
            èŠ‚ç‚¹ç‰¹å¾åˆ†æç»“æœ
        """
        if node_id not in self.all_nodes:
            return {'error': f'èŠ‚ç‚¹ä¸å­˜åœ¨: {node_id}'}
        
        # è·å–èŠ‚ç‚¹ä¿¡æ¯
        node_info = self.nodes_df[self.nodes_df['node_id'] == node_id].iloc[0]
        
        # è·å–èŠ‚ç‚¹åµŒå…¥
        embeddings = self.predictor.get_node_embeddings([node_id])
        
        # åˆ†æè¿æ¥æ€§
        connections = self.predict_node_connections(node_id, top_k=5)
        
        return {
            'node_id': node_id,
            'node_features': {
                'molecular_diff': float(node_info.get('molecular_diff', 0)),
                'rcu_count': int(node_info.get('rcu_count', 0)),
                'total_count': int(node_info.get('total_count', 0)),
                'substrate_count': int(node_info.get('substrate_count', 0)),
                'product_count': int(node_info.get('product_count', 0)),
                'ko_count': int(node_info.get('ko_count', 0)),
                'next_node_count': int(node_info.get('next_node_count', 0))
            },
            'embeddings': embeddings[node_id].tolist() if node_id in embeddings else None,
            'top_connections': connections['top_connections'],
            'connectivity_stats': connections['statistics']
        }
    
    def _get_confidence_level(self, probability: float) -> str:
        """è·å–ç½®ä¿¡åº¦ç­‰çº§"""
        if probability > 0.8 or probability < 0.2:
            return 'High'
        elif probability > 0.6 or probability < 0.4:
            return 'Medium'
        else:
            return 'Low'
    
    def _build_pathways(self, nodes: List[str], edge_predictions: Dict, 
                       max_length: int, min_probability: float) -> List[Dict]:
        """æ„å»ºä»£è°¢é€šè·¯ï¼šå¯¹å°è§„æ¨¡èŠ‚ç‚¹é›†æšä¸¾å…¨æ’åˆ—ï¼Œä½¿ç”¨æœ‰å‘è¾¹æ¦‚ç‡æ‰“åˆ†"""
        from itertools import permutations
        pathways = []

        # è¿‡æ»¤æœ‰æ•ˆè¾¹
        valid_edges = {edge: prob for edge, prob in edge_predictions.items()
                       if prob >= min_probability}

        if not valid_edges:
            return pathways

        unique_nodes = list(dict.fromkeys(nodes))
        unique_node_count = len(unique_nodes)

        # å¯¹å°è§„æ¨¡é—®é¢˜ï¼ˆä¾‹å¦‚4ä¸ªèŠ‚ç‚¹ï¼‰æšä¸¾æ‰€æœ‰æ’åˆ—
        for perm in permutations(unique_nodes, unique_node_count):
            path_nodes = list(perm)
            path_edges = []
            total_score = 0.0
            valid_path = True

            # æŒ‰æ’åˆ—é¡ºåºæ£€æŸ¥ç›¸é‚»æœ‰å‘è¾¹
            for i in range(len(path_nodes) - 1):
                edge_key = (path_nodes[i], path_nodes[i + 1])
                prob = valid_edges.get(edge_key, 0.0)
                if prob <= 0.0:
                    valid_path = False
                    break
                path_edges.append({
                    'from': path_nodes[i],
                    'to': path_nodes[i + 1],
                    'probability': prob
                })
                total_score += prob

            if not valid_path:
                continue

            pathways.append({
                'nodes': path_nodes,
                'edges': path_edges,
                'length': len(path_nodes),
                'score': total_score / len(path_edges) if path_edges else 0.0,
                'total_probability': total_score
            })

        # å»é‡ä¸æ’åº
        unique_pathways = []
        seen = set()
        for p in pathways:
            k = tuple(p['nodes'])
            if k not in seen:
                seen.add(k)
                unique_pathways.append(p)

        unique_pathways.sort(key=lambda x: x['score'], reverse=True)
        return unique_pathways
    
    def _build_single_pathway(self, start_node: str, all_nodes: List[str], 
                            valid_edges: Dict, max_length: int) -> Dict:
        """æ„å»ºå•ä¸ªè·¯å¾„"""
        path_nodes = [start_node]
        path_edges = []
        total_score = 0
        used_nodes = {start_node}
        
        current_node = start_node
        
        for _ in range(max_length - 1):
            best_next = None
            best_prob = 0
            
            # å¯»æ‰¾æœ€ä½³ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
            for next_node in all_nodes:
                if next_node in used_nodes:
                    continue
                
                edge_key1 = (current_node, next_node)
                # ä»…ä½¿ç”¨æœ‰å‘è¾¹æ¦‚ç‡
                prob = valid_edges.get(edge_key1, 0)
                
                if prob > best_prob:
                    best_prob = prob
                    best_next = next_node
            
            if best_next is None or best_prob == 0:
                break
            
            # æ·»åŠ åˆ°è·¯å¾„
            path_nodes.append(best_next)
            path_edges.append({
                'from': current_node,
                'to': best_next,
                'probability': best_prob
            })
            total_score += best_prob
            used_nodes.add(best_next)
            current_node = best_next
        
        return {
            'nodes': path_nodes,
            'edges': path_edges,
            'length': len(path_nodes),
            'score': total_score / len(path_edges) if path_edges else 0,
            'total_probability': total_score
        }
    
    def _find_paths_with_intermediates(self, source: str, target: str, 
                                     num_intermediate: int, min_prob: float) -> List[Dict]:
        """å¯»æ‰¾é€šè¿‡æŒ‡å®šæ•°é‡ä¸­é—´èŠ‚ç‚¹çš„è·¯å¾„"""
        paths = []
        
        # ç®€åŒ–å®ç°ï¼šéšæœºé€‰æ‹©ä¸­é—´èŠ‚ç‚¹è¿›è¡Œæµ‹è¯•
        import random
        candidate_intermediates = [node for node in self.all_nodes 
                                 if node not in [source, target]]
        
        # é™åˆ¶æœç´¢ç©ºé—´
        if len(candidate_intermediates) > 50:
            candidate_intermediates = random.sample(candidate_intermediates, 50)
        
        from itertools import combinations
        
        for intermediate_combo in combinations(candidate_intermediates, num_intermediate):
            # æ„å»ºè·¯å¾„ï¼šsource -> intermediate1 -> ... -> intermediateN -> target
            full_path = [source] + list(intermediate_combo) + [target]
            
            # æ£€æŸ¥æ‰€æœ‰è¾¹çš„æ¦‚ç‡
            path_edges = []
            total_prob = 1.0
            valid_path = True
            
            for i in range(len(full_path) - 1):
                edge_prob = self.predictor.predict_single_pair(full_path[i], full_path[i + 1])['probability']
                
                if edge_prob < min_prob:
                    valid_path = False
                    break
                
                path_edges.append({
                    'from': full_path[i],
                    'to': full_path[i + 1],
                    'probability': edge_prob
                })
                total_prob *= edge_prob
            
            if valid_path:
                paths.append({
                    'path': full_path,
                    'length': len(full_path) - 1,
                    'total_probability': total_prob,
                    'avg_probability': total_prob ** (1.0 / len(path_edges)),
                    'edges': path_edges
                })
        
        return paths


def main():
    """æ¼”ç¤ºèŠ‚ç‚¹é¢„æµ‹åŠŸèƒ½"""
    print("ğŸš€ KEGGèŠ‚ç‚¹é¢„æµ‹å™¨æ¼”ç¤º")
    print("=" * 60)
    
    # åˆå§‹åŒ–é¢„æµ‹å™¨
    predictor = KEGGNodePredictor()
    
    # è·å–ä¸€äº›ç¤ºä¾‹èŠ‚ç‚¹
    sample_nodes = predictor.all_nodes[:10]
    print(f"ğŸ“‹ ç¤ºä¾‹èŠ‚ç‚¹: {sample_nodes}")
    
    # 1. èŠ‚ç‚¹è¿æ¥é¢„æµ‹
    print("\nğŸ¯ 1. èŠ‚ç‚¹è¿æ¥é¢„æµ‹æ¼”ç¤º")
    target_node = sample_nodes[0]
    connections = predictor.predict_node_connections(target_node, top_k=5)
    
    print(f"ç›®æ ‡èŠ‚ç‚¹: {connections['query_node']}")
    print(f"å€™é€‰èŠ‚ç‚¹æ•°: {connections['total_candidates']}")
    print(f"æœ‰æ•ˆé¢„æµ‹æ•°: {connections['valid_predictions']}")
    print("å‰5ä¸ªè¿æ¥:")
    for conn in connections['top_connections']:
        print(f"  {conn['target_node']}: {conn['probability']:.4f} ({conn['confidence']})")
    
    # 2. ä»£è°¢é€šè·¯é¢„æµ‹
    print("\nğŸ›¤ï¸  2. ä»£è°¢é€šè·¯é¢„æµ‹æ¼”ç¤º")
    pathway_nodes = sample_nodes[:4]
    pathways = predictor.predict_pathway_from_nodes(pathway_nodes)
    
    print(f"è¾“å…¥èŠ‚ç‚¹: {pathways['input_nodes']}")
    print(f"æœ‰æ•ˆèŠ‚ç‚¹: {pathways['valid_nodes']}")
    print(f"å‘ç°é€šè·¯æ•°: {pathways['statistics']['total_pathways']}")
    
    if pathways['pathways']:
        best_pathway = pathways['pathways'][0]
        print(f"æœ€ä½³é€šè·¯: {' â†’ '.join(best_pathway['nodes'])}")
        print(f"é€šè·¯å¾—åˆ†: {best_pathway['score']:.4f}")
    
    # 3. è¿æ¥è·¯å¾„å‘ç°
    print("\nğŸ” 3. è¿æ¥è·¯å¾„å‘ç°æ¼”ç¤º")
    source, target = sample_nodes[0], sample_nodes[3]
    connecting_paths = predictor.find_connecting_nodes(source, target)
    
    print(f"æºèŠ‚ç‚¹: {connecting_paths['source_node']}")
    print(f"ç›®æ ‡èŠ‚ç‚¹: {connecting_paths['target_node']}")
    print(f"ç›´æ¥è¿æ¥æ¦‚ç‡: {connecting_paths['direct_connection']['probability']:.4f}")
    print(f"å‘ç°è·¯å¾„æ•°: {connecting_paths['statistics']['total_paths_found']}")
    
    if connecting_paths['connecting_paths']:
        best_path = connecting_paths['connecting_paths'][0]
        print(f"æœ€ä½³è·¯å¾„: {' â†’ '.join(best_path['path'])}")
        print(f"è·¯å¾„æ¦‚ç‡: {best_path['total_probability']:.4f}")
    
    # 4. èŠ‚ç‚¹ç‰¹å¾åˆ†æ
    print("\nğŸ“Š 4. èŠ‚ç‚¹ç‰¹å¾åˆ†ææ¼”ç¤º")
    node_analysis = predictor.analyze_node_features(sample_nodes[0])
    
    print(f"èŠ‚ç‚¹ID: {node_analysis['node_id']}")
    print("èŠ‚ç‚¹ç‰¹å¾:")
    for feature, value in node_analysis['node_features'].items():
        print(f"  {feature}: {value}")
    
    print("è¿æ¥æ€§ç»Ÿè®¡:")
    stats = node_analysis['connectivity_stats']
    print(f"  æœ€å¤§æ¦‚ç‡: {stats['max_probability']:.4f}")
    print(f"  å¹³å‡æ¦‚ç‡: {stats['avg_probability']:.4f}")
    print(f"  è¿æ¥æ•°: {stats['connected_count']}")
    
    print("\nâœ… èŠ‚ç‚¹é¢„æµ‹æ¼”ç¤ºå®Œæˆ!")


if __name__ == "__main__":
    main()